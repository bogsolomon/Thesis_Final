% Chapter 1

\chapter{Introduction} % Write in your own chapter title
\label{Chapter_introduction}
\lhead{Chapter \ref{Chapter_introduction}. \emph{Introduction}} % Write in your own chapter title to set the page header

\section{Motivation and Research Objectives}

As IT departments have become more pervasive and more important for each and every company, as well as to our daily lives, they have also become more complex. In today's world people obtain their news and alerts online, shop online as well as communicate with friends and family via social networking sites. The complexity of the IT infrastructure has lead however to a situation where it is nearly impossible for humans to continue to manage and maintain the IT resources in a good state. Failures of the IT infrastructure in a company can have disastrous consequences for the company or even for the economy. In a world that is as fast as the current one an IT failure can result in lost sales, loss of customers to competitors or even payment of damages depending on how critical the infrastructure is.

Cloud computing exacerbates these issues by moving the IT infrastructure outside a company's premises. Where before each small enterprise would run its own small IT department, now large data centers provide IT services to multiple consumers and enterprises (SaaS, HaaS, IaaS). For the cloud providers, the ability to maintain the systems' service level agreements and prevent service outages is paramount since long period of failures can open them to large liabilities from their customers. At the same time, cloud computing provides the ability for companies to pay only for the required resources and to scale up or down as more resources are needed or as resources are no longer required. Due to this capability, a solution is needed for cloud computing users in order to intelligently decide when to request more servers and when to release used servers. From the point of view of cloud computing providers, a solution is needed in order to move server loads such that only the required resources are used for a certain demand via virtualization. Server virtualization also increases the complexity of managing the servers in data centers, since suddenly one single hardware server can be running tens of virtual machines, each with its own load and processing requirements. Ensuring that the appropriate number of virtual machines are deployed on a hardware platform, such that the hardware is neither underutilized, nor that the virtual machines starve each other for resources, is not a trivial administrative task. The issue becomes even more complex when the end user's location is taken into consideration. In order to achieve better response times and latency, it is preferable to offer services as close as possible to the end user. Such approaches can be seen in Content Delivery Networks (CDNs) \cite{akamai}, which cache web data in datacenters across the world in order to be closer to the end users. A similar approach is taken by Netflix in order to cache the most viewed shows and movies closer to the customers.

These are the problems that autonomic management systems attempt to solve. Autonomic computing systems are capable of self-managing by self-configuring, self-healing, self-optimizing and self-protecting, together known as self-CHOP. Such a system must be able to analyze itself at run time, determine its state, determine a desired state and then if necessary attempt to reach the desired state from the current state. Normally the desired state is a state that maintains the system's Service Level Agreement (SLA). For a self-configuring system for example, this could include finding missing libraries and installing them with no human intervention. A self-healing system would be able to determine errors in execution and recover to a known safe state. A self-optimizing system example would be a cluster of servers that dynamically adds and removes servers at run time in order to maintain a certain utilization and client response time. Finally, a self-protecting system example would be a server that detects a denial of service (DoS) attack and prevents it by refusing requests from certain Internet Protocol (IP) addresses.

The above goals of autonomic computing were mapped in the Manifesto \cite{IBM:AutonomicManifesto} containing eight key requirements that a system must meet to be considered autonomic. An autonomic computing system must:

\begin{enumerate}
	\item ``Know itself'' by knowing its components, status, ultimate capacity, and other interconnected systems
	\item Configure and reconfigure itself under various and sometimes unpredictable situations. The configuration must be done automatically by the system
	\item Never settle for the status quo, and must always try to optimize the available resources, itself, and the way it works
	\item Be able to heal itself in case of malfunctions on some of its parts, and be able to recover its normal state of execution
	\item Be able to protect itself by identifying and responding to threats against various types of attacks, while maintaining system integrity and security
	\item Be aware of its environment and act according to the environmental needs
	\item Function in a heterogeneous and open way, and implement open standards
	\item Keep its complexity hidden from the end user
\end{enumerate}

Since the release of the Manifesto, a number of research directions and a corresponding number of projects have been developed to look at how to create such intelligent systems which can substitute human intervention with automatically generated operative commands. Various approaches have been taken to reach the desired system self-adaptation qualities. In terms of how the self-management behavior is reached two main architecture approaches have been used. In the first approach, a global controller is added to the system, which gathers data from the various components, performs some form of analysis on the data, and compares the analysis results with the desired goals. If the goals are breached by the predicted analysis, corrective actions are taken. Such approaches are seen in \cite{related:architecture:hierarch1}, \cite{related:model:lqm} and \cite{bogdan:seams07}. In the first type of approaches, a cluster of servers would (for example) have one controller which manages the entire cluster's adaptation. The second approach attempts to develop an autonomic system by developing small intelligent subsystems which achieve global self-adaptation through the interactions with other components. Such approaches can be seen in \cite{related:architecture:selflet} and \cite{related:architecture:unity}. In this second approach, each server in a cluster would have its own intelligence which achieves local adaptation. The communication between components is then used in order to reach global system adaptation. Such systems can be developed by looking at Self-Organizing systems, which are systems that are capable of reaching a desired state without the use of any central authority or plan. This type of system can be seen in Ashby's homeostat \cite{ashby:homeostat} which is capable of adapting itself to any perturbation in the system and reach back a stable state. Self-Organizing Networks have also been developed in recent years for mobile networks.

In this thesis, a \textbf{Self-Organizing autonomic system} which self-manages a cloud of servers is introduced. The system architecture, system design and results obtained via simulations and experiments with a live system are presented. The self-managing function ensures that all the servers in the same data-center maintain the same response time and CPU usage. At the same time, the self-organizing system can add or remove servers as needed when load for the service increases or decreases.

The motivation for developing an autonomic computing system to manage the cloud deployment is related to providing intelligent scaling of the cloud resources such that only the required resources are used at a given point in time. With the autonomic system managing the cloud resources, it can be ensured that servers are not idle when users do not need them. At the same time when demand increases the autonomic system ensures that more servers are started such that the latency and response time of the system are maintained at desired levels.

\section{Organization of the Thesis and Research Focus}

The thesis is organized such that it presents the self-organizing autonomic system moving from the design of the autonomic control system to various mechanisms which have to be set up to ensure the self-optimization of the cloud resources usage. Simulation results as well as results from a live system are also shown. The rest of the thesis comprises the following.

Chapter \ref{Chapter_related} presents the goals of the self-organizing system and also presents various related work in both autonomic architectures and self-organizing problems.

Chapter \ref{Chapter_selforg} describes the self-organization approach for the self-optimizing control of cloud resources. In this case self-optimization refers to providing automatic elasticity for the cloud. The self-optimizing system is split into two algorithms. The first algorithm is responsible for predicting SLA breaches and the second algorithm optimizes the size of the cloud when faced with SLA breaches.

Chapter \ref{Chapter_testbed} presents a cloud simulation environment used to compare the proposed system with other auto-scaling systems as well as a test bed running a collaborative application.

Chapter \ref{Chapter_results} shows the performance tests for the self-organizing self-optimizing system which were obtained in the simulation environment and on the test bed.

Finally chapter \ref{Chapter_conclusions} presents conclusions of the benefits provided by the proposed solution. Future developments of the architecture are also described.

The thesis' research focus will be on a number of contributions to the field of autonomic computing and self-organizing systems, as presented in \cite{bogdan:lindi}, \cite{bogdan:amgcc2013}, \cite{bogdan:cts2012}, \cite{bogdan:conti2010}, \cite{bogdan:saci2013} and \cite{bogdan:miles2012chapter}. 

The research will focus on a new self-organizing approach used for server scaling in data-centers and cloud systems which will allow heterogeneous resources to be part of the same server cloud, while normally a self scaling system will use homogeneous only resources. The designed self-organizing self-optimizing system will be split in two parts: a self-organizing system responsible for predicting breaches of the cloud's SLA and a second self-organizing algorithm which optimizes the number of servers used in the cloud when a breach is detected.

A simulation environment and test-bed are used in order to obtain results on the performance of the self-organizing autonomic system while managing various types of cloud resources - showing the versatility of the proposed approach.